{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f77b85ad-9d57-41c9-87ba-c5c0ab43490e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'xarray.core.dataarray.DataArray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m Te\u001b[38;5;241m=\u001b[39mm_1\u001b[38;5;241m/\u001b[39mm0; \u001b[38;5;66;03m#Energy wave period\u001b[39;00m\n\u001b[1;32m     46\u001b[0m WP\u001b[38;5;241m=\u001b[39m((\u001b[38;5;241m1025\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m9.8\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi))\u001b[38;5;241m*\u001b[39mTe\u001b[38;5;241m*\u001b[39mHs\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m;  \u001b[38;5;66;03m#Wave power\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mHs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mWP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     49\u001b[0m final_result\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([final_result,result])  \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'xarray.core.dataarray.DataArray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "#Calculating wave energy and wave parameters from NC files corresponding *_SPT.txt data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "path = \"*.nc\"\n",
    "files=glob.glob(path)\n",
    "start_period=1 # If full range need to calculate give value 1 here\n",
    "end_period=40  # If full range need to calculate give value 40 here\n",
    "final_result=pd.DataFrame()\n",
    "for file in files:\n",
    "    data=xr.open_dataset(file)\n",
    "    time=data.time\n",
    "    S=data.SmaxXpsd\n",
    "    frq=data.Frequency\n",
    "    frq=pd.DataFrame(frq)\n",
    "    df = frq.diff()\n",
    "    df=df.squeeze() #Converting dataframe to pandas series \n",
    "    df=df[1:] \n",
    "    f=frq.rolling(window=2).mean() #Averaging one value with next one\n",
    "    f=f[1:]\n",
    "    #f_init=1/end_period\n",
    "    #f_final=1/start_period \n",
    "    #f_init_ind =abs(f - f_init).idxmin() #Find index corresponding to give frequencies\n",
    "    #f_final_ind=abs(f - f_final).idxmin()\n",
    "    final_result=[]\n",
    "    for t in times:\n",
    "        spec=pd.DataFrame(S.sel(time=t)) #Selecting spectral moment from data\n",
    "        spec=spec.squeeze()\n",
    "        s=spec.rolling(window=2).mean()\n",
    "        s=s[1:] \n",
    "        ss0=df*s\n",
    "        ss1=f*s*df\n",
    "        ss2=f**2*s*df\n",
    "        ss_1=f**-1*s*df\n",
    "        m0=ss0.sum() #Calculating zeroth moment\n",
    "        m1=ss1.sum()\n",
    "        m2=ss2.sum()\n",
    "        m_1=ss_1.sum() \n",
    "        Hs=4*np.sqrt(m0)\n",
    "        Tz=np.sqrt(m0/m2);\n",
    "        Tm=m0/m1; #Mean wave period\n",
    "        Te=m_1/m0; #Energy wave period\n",
    "        WP=((1025*(9.8)**2)/(64*np.pi))*Te*Hs**2;  #Wave power\n",
    "        result=pd.concat([t,Hs.round(2),Tz.round(2),Tm.round(2),Te.round(2),WP.round(2)],axis=1)\n",
    "        print(result)\n",
    "        final_result=pd.concat([final_result,result])  \n",
    "#final_result=pd.DataFrame(final_result,columns = [\"Time\",\"Hs\",\"Tz\",\"Tm\",\"Te\",\"WP\"])\n",
    "#final_result.to_csv(\"Wave_Ene_{}.csv\".format(file[:-3]),index=False)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcda8847-2b1b-40cd-8427-127a9c76fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2110/505140016.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_result = pd.concat([final_result, result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Time    Hs    Tz    Tm    Te       WP\n",
      "0    2010-09-01 00:28:00  1.52  5.32  6.06  7.82  8870.87\n",
      "1    2010-09-01 00:58:00  1.59  5.47  6.25  8.08  9996.99\n",
      "2    2010-09-01 01:28:00  1.49  5.39  6.07  7.63  8305.20\n",
      "3    2010-09-01 01:58:00  1.61  5.45  6.08  7.59  9614.72\n",
      "4    2010-09-01 02:28:00  1.62  5.51  6.14  7.61  9764.73\n",
      "...                  ...   ...   ...   ...   ...      ...\n",
      "1435 2010-09-30 21:58:00  0.83  4.92  5.86  7.97  2658.27\n",
      "1436 2010-09-30 22:28:00  0.82  4.94  5.94  8.13  2706.81\n",
      "1437 2010-09-30 22:58:00  0.79  5.27  6.36  8.62  2643.34\n",
      "1438 2010-09-30 23:28:00  0.76  5.46  6.56  8.64  2440.36\n",
      "1439 2010-09-30 23:58:00  0.72  5.43  6.51  8.71  2239.71\n",
      "\n",
      "[1440 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "# Define the file path and search for .nc files\n",
    "path = \"*.nc\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "# Define the frequency range (adjust if using full range)\n",
    "start_period = 1  # Minimum frequency\n",
    "end_period = 40  # Maximum frequency\n",
    "\n",
    "# Initialize the final result DataFrame\n",
    "final_result = pd.DataFrame(columns=[\"Time\", \"Hs\", \"Tz\", \"Tm\", \"Te\", \"WP\"])\n",
    "\n",
    "# Loop through each file in the list of .nc files\n",
    "for file in files:\n",
    "    # Open the netCDF file\n",
    "    data = xr.open_dataset(file)\n",
    "    \n",
    "    # Extract variables from the dataset\n",
    "    times = data.time\n",
    "    S = data.SmaxXpsd\n",
    "    frq = data.Frequency\n",
    "\n",
    "    # Convert the Frequency data to a pandas Series\n",
    "    frq = pd.Series(frq.values.squeeze())\n",
    "    df = frq.diff().dropna()  # Difference between adjacent frequency values\n",
    "    \n",
    "    # Calculate rolling mean of frequency (average one value with the next one)\n",
    "    f = frq.rolling(window=2).mean().dropna()\n",
    "\n",
    "    # Loop through each time step\n",
    "    for t in times:\n",
    "        # Select the spectral moment for the current time\n",
    "        spec = pd.Series(S.sel(time=t).values.squeeze())\n",
    "        s = spec.rolling(window=2).mean().dropna()\n",
    "\n",
    "        # Calculate moments by integrating over the frequency range\n",
    "        ss0 = df * s\n",
    "        ss1 = f * s * df\n",
    "        ss2 = f**2 * s * df\n",
    "        ss_1 = f**-1 * s * df\n",
    "\n",
    "        # Calculate wave parameters\n",
    "        m0 = ss0.sum()  # Zeroth moment\n",
    "        m1 = ss1.sum()  # First moment\n",
    "        m2 = ss2.sum()  # Second moment\n",
    "        m_1 = ss_1.sum()  # Negative first moment\n",
    "\n",
    "        Hs = 4 * np.sqrt(m0)  # Significant wave height\n",
    "        Tz = np.sqrt(m0 / m2)  # Zero-crossing period\n",
    "        Tm = m0 / m1  # Mean wave period\n",
    "        Te = m_1 / m0  # Energy wave period\n",
    "        WP = ((1025 * (9.8)**2) / (64 * np.pi)) * Te * Hs**2  # Wave power\n",
    "\n",
    "        # Create a row for this time step's results\n",
    "        result = pd.DataFrame({\n",
    "            \"Time\": [pd.to_datetime(t.values)],\n",
    "            \"Hs\": [Hs.round(2)],\n",
    "            \"Tz\": [Tz.round(2)],\n",
    "            \"Tm\": [Tm.round(2)],\n",
    "            \"Te\": [Te.round(2)],\n",
    "            \"WP\": [WP.round(2)]\n",
    "        })\n",
    "\n",
    "        # Append the results for this time step to the final result DataFrame\n",
    "        final_result = pd.concat([final_result, result], ignore_index=True)\n",
    "\n",
    "# Output the final result DataFrame\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "786426e2-5f1f-4c82-aaf2-682a0f9d6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2110/2105556970.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_result = pd.concat([final_result, result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Time    Hs    Tz    Tm    Te       WP\n",
      "0    2010-09-01 00:28:00  1.52  5.32  6.06  7.82  8870.87\n",
      "1    2010-09-01 00:58:00  1.59  5.47  6.25  8.08  9996.99\n",
      "2    2010-09-01 01:28:00  1.49  5.39  6.07  7.63  8305.20\n",
      "3    2010-09-01 01:58:00  1.61  5.45  6.08  7.59  9614.72\n",
      "4    2010-09-01 02:28:00  1.62  5.51  6.14  7.61  9764.73\n",
      "...                  ...   ...   ...   ...   ...      ...\n",
      "1435 2010-09-30 21:58:00  0.83  4.92  5.86  7.97  2658.27\n",
      "1436 2010-09-30 22:28:00  0.82  4.94  5.94  8.13  2706.81\n",
      "1437 2010-09-30 22:58:00  0.79  5.27  6.36  8.62  2643.34\n",
      "1438 2010-09-30 23:28:00  0.76  5.46  6.56  8.64  2440.36\n",
      "1439 2010-09-30 23:58:00  0.72  5.43  6.51  8.71  2239.71\n",
      "\n",
      "[1440 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "# Define the file path and search for .nc files\n",
    "path = \"*.nc\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "# Define the frequency range (adjust if using full range)\n",
    "start_period = 1  # Minimum frequency\n",
    "end_period = 40  # Maximum frequency\n",
    "\n",
    "# Initialize the final result DataFrame\n",
    "final_result = pd.DataFrame(columns=[\"Time\", \"Hs\", \"Tz\", \"Tm\", \"Te\", \"WP\"])\n",
    "\n",
    "# Loop through each file in the list of .nc files\n",
    "for file in files:\n",
    "    # Open the netCDF file\n",
    "    data = xr.open_dataset(file)\n",
    "    \n",
    "    # Extract variables from the dataset\n",
    "    times = data.time\n",
    "    S = data.SmaxXpsd\n",
    "    frq = data.Frequency\n",
    "\n",
    "    # Convert the Frequency data to a pandas Series\n",
    "    frq = pd.Series(frq.values.squeeze())\n",
    "    df = frq.diff().dropna()  # Difference between adjacent frequency values\n",
    "    \n",
    "    # Calculate rolling mean of frequency (average one value with the next one)\n",
    "    f = frq.rolling(window=2).mean().dropna()\n",
    "\n",
    "    # Loop through each time step\n",
    "    for t in times:\n",
    "        # Select the spectral moment for the current time\n",
    "        spec = pd.Series(S.sel(time=t).values.squeeze())\n",
    "        s = spec.rolling(window=2).mean().dropna()\n",
    "\n",
    "        # Calculate moments by integrating over the frequency range\n",
    "        ss0 = df * s\n",
    "        ss1 = f * s * df\n",
    "        ss2 = f**2 * s * df\n",
    "        ss_1 = f**-1 * s * df\n",
    "\n",
    "        # Calculate wave parameters\n",
    "        m0 = ss0.sum()  # Zeroth moment\n",
    "        m1 = ss1.sum()  # First moment\n",
    "        m2 = ss2.sum()  # Second moment\n",
    "        m_1 = ss_1.sum()  # Negative first moment\n",
    "\n",
    "        Hs = 4 * np.sqrt(m0)  # Significant wave height\n",
    "        Tz = np.sqrt(m0 / m2)  # Zero-crossing period\n",
    "        Tm = m0 / m1  # Mean wave period\n",
    "        Te = m_1 / m0  # Energy wave period\n",
    "        WP = ((1025 * (9.8)**2) / (64 * np.pi)) * Te * Hs**2  # Wave power\n",
    "\n",
    "        # Create a row for this time step's results\n",
    "        result = pd.DataFrame({\n",
    "            \"Time\": [pd.to_datetime(t.values)],\n",
    "            \"Hs\": [Hs.round(2)],\n",
    "            \"Tz\": [Tz.round(2)],\n",
    "            \"Tm\": [Tm.round(2)],\n",
    "            \"Te\": [Te.round(2)],\n",
    "            \"WP\": [WP.round(2)]\n",
    "        })\n",
    "\n",
    "        # Only append if result has no empty or all-NaN entries\n",
    "        if not result.isnull().all().all():\n",
    "            final_result = pd.concat([final_result, result], ignore_index=True)\n",
    "\n",
    "# Output the final result DataFrame\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e449e11-c524-4694-8cc4-c96b5dbed37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2110/2436393418.py:74: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_result = pd.concat([final_result, result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Time    Hs    Tz    Tm    Te       WP\n",
      "0    2010-09-01 00:28:00  1.52  5.32  6.06  7.82  8870.87\n",
      "1    2010-09-01 00:58:00  1.59  5.47  6.25  8.08  9996.99\n",
      "2    2010-09-01 01:28:00  1.49  5.39  6.07  7.63  8305.20\n",
      "3    2010-09-01 01:58:00  1.61  5.45  6.08  7.59  9614.72\n",
      "4    2010-09-01 02:28:00  1.62  5.51  6.14  7.61  9764.73\n",
      "...                  ...   ...   ...   ...   ...      ...\n",
      "1435 2010-09-30 21:58:00  0.83  4.92  5.86  7.97  2658.27\n",
      "1436 2010-09-30 22:28:00  0.82  4.94  5.94  8.13  2706.81\n",
      "1437 2010-09-30 22:58:00  0.79  5.27  6.36  8.62  2643.34\n",
      "1438 2010-09-30 23:28:00  0.76  5.46  6.56  8.64  2440.36\n",
      "1439 2010-09-30 23:58:00  0.72  5.43  6.51  8.71  2239.71\n",
      "\n",
      "[1440 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "# Define the file path and search for .nc files\n",
    "path = \"*.nc\"\n",
    "files = glob.glob(path)\n",
    "\n",
    "# Define the frequency range (adjust if using full range)\n",
    "start_period = 1  # Minimum frequency\n",
    "end_period = 40  # Maximum frequency\n",
    "\n",
    "# Initialize the final result DataFrame\n",
    "final_result = pd.DataFrame(columns=[\"Time\", \"Hs\", \"Tz\", \"Tm\", \"Te\", \"WP\"])\n",
    "\n",
    "# Loop through each file in the list of .nc files\n",
    "for file in files:\n",
    "    # Open the netCDF file\n",
    "    data = xr.open_dataset(file)\n",
    "    \n",
    "    # Extract variables from the dataset\n",
    "    times = data.time\n",
    "    S = data.SmaxXpsd\n",
    "    frq = data.Frequency\n",
    "\n",
    "    # Convert the Frequency data to a pandas Series\n",
    "    frq = pd.Series(frq.values.squeeze())\n",
    "    df = frq.diff().dropna()  # Difference between adjacent frequency values\n",
    "    \n",
    "    # Calculate rolling mean of frequency (average one value with the next one)\n",
    "    f = frq.rolling(window=2).mean().dropna()\n",
    "\n",
    "    # Loop through each time step\n",
    "    for t in times:\n",
    "        # Select the spectral moment for the current time\n",
    "        spec = pd.Series(S.sel(time=t).values.squeeze())\n",
    "        s = spec.rolling(window=2).mean().dropna()\n",
    "\n",
    "        # Calculate moments by integrating over the frequency range\n",
    "        ss0 = df * s\n",
    "        ss1 = f * s * df\n",
    "        ss2 = f**2 * s * df\n",
    "        ss_1 = f**-1 * s * df\n",
    "\n",
    "        # Calculate wave parameters\n",
    "        m0 = ss0.sum()  # Zeroth moment\n",
    "        m1 = ss1.sum()  # First moment\n",
    "        m2 = ss2.sum()  # Second moment\n",
    "        m_1 = ss_1.sum()  # Negative first moment\n",
    "\n",
    "        Hs = 4 * np.sqrt(m0)  # Significant wave height\n",
    "        Tz = np.sqrt(m0 / m2)  # Zero-crossing period\n",
    "        Tm = m0 / m1  # Mean wave period\n",
    "        Te = m_1 / m0  # Energy wave period\n",
    "        WP = ((1025 * (9.8)**2) / (64 * np.pi)) * Te * Hs**2  # Wave power\n",
    "\n",
    "        # Create a row for this time step's results\n",
    "        result = pd.DataFrame({\n",
    "            \"Time\": [pd.to_datetime(t.values)],\n",
    "            \"Hs\": [Hs.round(2)],\n",
    "            \"Tz\": [Tz.round(2)],\n",
    "            \"Tm\": [Tm.round(2)],\n",
    "            \"Te\": [Te.round(2)],\n",
    "            \"WP\": [WP.round(2)]\n",
    "        })\n",
    "\n",
    "        # Filter out all-NaN columns in `result` to avoid warnings\n",
    "        result = result.dropna(axis=1, how='all')\n",
    "\n",
    "        # Only append if `result` has no empty or all-NaN entries\n",
    "        if not result.empty:\n",
    "            final_result = pd.concat([final_result, result], ignore_index=True)\n",
    "\n",
    "# Output the final result DataFrame\n",
    "print(final_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
