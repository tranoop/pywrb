{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ecb5a3-984e-4aa3-9458-924668b807b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3ea09a-4891-47af-8cbc-72ad0f1eca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  Hs_swell    Hs_sea  fswell_peak  fsea_peak\n",
      "0    2018-05-15 06:30:00  0.000000  0.035214       0.0275     0.0375\n",
      "1    2018-05-15 07:00:00  0.411388  0.313560       0.0825     0.1850\n",
      "2    2018-05-15 07:30:00  0.541886  0.720833       0.0675     0.2050\n",
      "3    2018-05-15 08:00:00  0.517726  0.699600       0.0675     0.1950\n",
      "4    2018-05-15 08:30:00  0.497936  0.665552       0.0675     0.1950\n",
      "...                  ...       ...       ...          ...        ...\n",
      "3727 2018-07-31 22:00:00  1.559391  1.201233       0.0975     0.1550\n",
      "3728 2018-07-31 22:30:00  1.597442  1.169718       0.0975     0.1550\n",
      "3729 2018-07-31 23:00:00  1.632354  1.201932       0.0925     0.1450\n",
      "3730 2018-07-31 23:30:00  1.440597  1.235055       0.0975     0.1450\n",
      "3731 2018-08-01 00:00:00  1.605628  1.076550       0.0975     0.1550\n",
      "\n",
      "[3732 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import glob\n",
    "import warnings\n",
    "results = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "files = glob.glob(\"*.nc\")\n",
    "for file in files:\n",
    "    data = xr.open_dataset(file)\n",
    "    date = data.time.values  # Extract date array\n",
    "    S = data.SmaxXpsd.values  # Extract SmaxXpsd array\n",
    "    f = data.Frequency.values  # Extract frequency array\n",
    "    spec = (S[:, 1:] + S[:, :63]) * 0.5\n",
    "    freq = (f[1:] + f[:63]) * 0.5\n",
    "    df = np.diff(f)\n",
    "    fup_indices = np.where(freq <= 0.5)[0]\n",
    "    fup = freq[fup_indices]\n",
    "\n",
    "    for i in range(len(S)):\n",
    "        spec_row = spec[i, :]\n",
    "        m1fstar = np.zeros(len(fup))\n",
    "        mminus1fstar = np.zeros(len(fup))\n",
    "        time = date[i]\n",
    "\n",
    "        for j in range(len(fup)):\n",
    "            m1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** 1 * df[j:len(fup)])\n",
    "            mminus1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** (-1) * df[j:len(fup)])\n",
    "\n",
    "        with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "            alfafstar = m1fstar / np.sqrt(mminus1fstar)\n",
    "\n",
    "        if np.all(np.isnan(alfafstar)):\n",
    "            continue\n",
    "\n",
    "        loc1 = np.nanargmax(alfafstar)\n",
    "        fm = fup[loc1]\n",
    "\n",
    "        fseparation = 24.2084 * fm**3 - 9.2021 * fm**2 + 1.8906 * fm - 0.04286\n",
    "        spec_trimmed = spec_row[0:len(fup)]\n",
    "        spec_df = pd.DataFrame(spec_trimmed)\n",
    "        fup_df = pd.DataFrame(fup)\n",
    "\n",
    "        f_swell = fup_df[fup_df < fseparation].dropna()\n",
    "        f_sea = fup_df[fup_df > fseparation].dropna()\n",
    "\n",
    "        if fseparation > 0.025:\n",
    "            df_swell = f_swell.diff()\n",
    "            df_sea = f_sea.diff()\n",
    "            spec_swell = spec_df.loc[f_swell.index]\n",
    "            spec_sea = spec_df.loc[f_sea.index]\n",
    "            f_sea.loc[spec_sea.idxmax()]\n",
    "            fswell_peak=f_swell.loc[spec_swell.idxmax()]\n",
    "            fsea_peak=f_sea.loc[spec_sea.idxmax()]\n",
    "            fswell_peak=fswell_peak.iloc[0, 0]\n",
    "            fsea_peak=fsea_peak.iloc[0, 0]\n",
    "            Hs_swell = 4 * np.sqrt(np.nansum(spec_swell.values.flatten() * df_swell.values.flatten()))\n",
    "            Hs_sea = 4 * np.sqrt(np.nansum(spec_sea.values.flatten() * df_sea.values.flatten()))\n",
    "\n",
    "            # Append results to the DataFrame\n",
    "            results = pd.concat(\n",
    "                [results, pd.DataFrame([[time, Hs_swell, Hs_sea,fswell_peak,fsea_peak]], columns=[\"Date\", \"Hs_swell\", \"Hs_sea\",\"fswell_peak\",\"fsea_peak\"])],\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4e3494-2325-4361-878c-07a0cbb2d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/OneDrive/WORK/Projects/WRB_Dataprocessing\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def process_wave_data(folder_path):\n",
    "    \"\"\"\n",
    "    Process wave data from .nc files in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing .nc files. Defaults to the current directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the processed results with columns:\n",
    "                      [\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"].\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(columns=[\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"])  # Initialize an empty DataFrame\n",
    "    files = glob.glob(f\"{folder_path}/*.nc\")  # Get all .nc files in the folder\n",
    "\n",
    "    for file in files:\n",
    "        data = xr.open_dataset(file)\n",
    "        date = data.time.values  # Extract date array\n",
    "        S = data.SmaxXpsd.values  # Extract SmaxXpsd array\n",
    "        f = data.Frequency.values  # Extract frequency array\n",
    "        spec = (S[:, 1:] + S[:, :63]) * 0.5\n",
    "        freq = (f[1:] + f[:63]) * 0.5\n",
    "        df = np.diff(f)\n",
    "        fup_indices = np.where(freq <= 0.5)[0]\n",
    "        fup = freq[fup_indices]\n",
    "\n",
    "        for i in range(len(S)):\n",
    "            spec_row = spec[i, :]\n",
    "            m1fstar = np.zeros(len(fup))\n",
    "            mminus1fstar = np.zeros(len(fup))\n",
    "            time = date[i]\n",
    "\n",
    "            for j in range(len(fup)):\n",
    "                m1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** 1 * df[j:len(fup)])\n",
    "                mminus1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** (-1) * df[j:len(fup)])\n",
    "\n",
    "            with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "                alfafstar = m1fstar / np.sqrt(mminus1fstar)\n",
    "\n",
    "            if np.all(np.isnan(alfafstar)):\n",
    "                continue\n",
    "\n",
    "            loc1 = np.nanargmax(alfafstar)\n",
    "            fm = fup[loc1]\n",
    "\n",
    "            fseparation = 24.2084 * fm**3 - 9.2021 * fm**2 + 1.8906 * fm - 0.04286\n",
    "            spec_trimmed = spec_row[0:len(fup)]\n",
    "            spec_df = pd.DataFrame(spec_trimmed)\n",
    "            fup_df = pd.DataFrame(fup)\n",
    "\n",
    "            f_swell = fup_df[fup_df < fseparation].dropna()\n",
    "            f_sea = fup_df[fup_df > fseparation].dropna()\n",
    "\n",
    "            if fseparation > 0.025:\n",
    "                df_swell = f_swell.diff()\n",
    "                df_sea = f_sea.diff()\n",
    "                spec_swell = spec_df.loc[f_swell.index]\n",
    "                spec_sea = spec_df.loc[f_sea.index]\n",
    "                fswell_peak = f_swell.loc[spec_swell.idxmax()].values[0]  # Extract scalar value\n",
    "                fsea_peak = f_sea.loc[spec_sea.idxmax()].values[0]  # Extract scalar value\n",
    "                Hs_swell = 4 * np.sqrt(np.nansum(spec_swell.values.flatten() * df_swell.values.flatten()))\n",
    "                Hs_sea = 4 * np.sqrt(np.nansum(spec_sea.values.flatten() * df_sea.values.flatten()))\n",
    "\n",
    "                # Append results to the DataFrame\n",
    "                results = pd.concat(\n",
    "                    [results, pd.DataFrame([[time, Hs_swell, Hs_sea, fswell_peak, fsea_peak]], columns=[\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"])],\n",
    "                    ignore_index=True\n",
    "                )\n",
    "\n",
    "    return results\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904ab7b6-3f18-4a71-9246-5ecf132fa1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5162/545502179.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hs_swell</th>\n",
       "      <th>Hs_sea</th>\n",
       "      <th>fswell_peak</th>\n",
       "      <th>fsea_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 06:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>[0.0275]</td>\n",
       "      <td>[0.037500000000000006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 07:00:00</td>\n",
       "      <td>0.411388</td>\n",
       "      <td>0.313560</td>\n",
       "      <td>[0.0825]</td>\n",
       "      <td>[0.185]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 07:30:00</td>\n",
       "      <td>0.541886</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>[0.0675]</td>\n",
       "      <td>[0.20500000000000002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 08:00:00</td>\n",
       "      <td>0.517726</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>[0.0675]</td>\n",
       "      <td>[0.195]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 08:30:00</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.665552</td>\n",
       "      <td>[0.0675]</td>\n",
       "      <td>[0.195]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>2018-07-31 22:00:00</td>\n",
       "      <td>1.559391</td>\n",
       "      <td>1.201233</td>\n",
       "      <td>[0.0975]</td>\n",
       "      <td>[0.155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>2018-07-31 22:30:00</td>\n",
       "      <td>1.597442</td>\n",
       "      <td>1.169718</td>\n",
       "      <td>[0.0975]</td>\n",
       "      <td>[0.155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>2018-07-31 23:00:00</td>\n",
       "      <td>1.632354</td>\n",
       "      <td>1.201932</td>\n",
       "      <td>[0.0925]</td>\n",
       "      <td>[0.14500000000000002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>2018-07-31 23:30:00</td>\n",
       "      <td>1.440597</td>\n",
       "      <td>1.235055</td>\n",
       "      <td>[0.0975]</td>\n",
       "      <td>[0.14500000000000002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2018-08-01 00:00:00</td>\n",
       "      <td>1.605628</td>\n",
       "      <td>1.076550</td>\n",
       "      <td>[0.0975]</td>\n",
       "      <td>[0.155]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3732 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date  Hs_swell    Hs_sea fswell_peak  \\\n",
       "0    2018-05-15 06:30:00  0.000000  0.035214    [0.0275]   \n",
       "1    2018-05-15 07:00:00  0.411388  0.313560    [0.0825]   \n",
       "2    2018-05-15 07:30:00  0.541886  0.720833    [0.0675]   \n",
       "3    2018-05-15 08:00:00  0.517726  0.699600    [0.0675]   \n",
       "4    2018-05-15 08:30:00  0.497936  0.665552    [0.0675]   \n",
       "...                  ...       ...       ...         ...   \n",
       "3727 2018-07-31 22:00:00  1.559391  1.201233    [0.0975]   \n",
       "3728 2018-07-31 22:30:00  1.597442  1.169718    [0.0975]   \n",
       "3729 2018-07-31 23:00:00  1.632354  1.201932    [0.0925]   \n",
       "3730 2018-07-31 23:30:00  1.440597  1.235055    [0.0975]   \n",
       "3731 2018-08-01 00:00:00  1.605628  1.076550    [0.0975]   \n",
       "\n",
       "                   fsea_peak  \n",
       "0     [0.037500000000000006]  \n",
       "1                    [0.185]  \n",
       "2      [0.20500000000000002]  \n",
       "3                    [0.195]  \n",
       "4                    [0.195]  \n",
       "...                      ...  \n",
       "3727                 [0.155]  \n",
       "3728                 [0.155]  \n",
       "3729   [0.14500000000000002]  \n",
       "3730   [0.14500000000000002]  \n",
       "3731                 [0.155]  \n",
       "\n",
       "[3732 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path=\"/mnt/e/OneDrive/WORK/Projects/WRB_Dataprocessing\"\n",
    "process_wave_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3a7bdc-3f9f-4184-a56d-241af0f438dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5162/2663028708.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  Hs_swell    Hs_sea  fswell_peak  fsea_peak\n",
      "0    2018-05-15 06:30:00  0.000000  0.035214       0.0275     0.0375\n",
      "1    2018-05-15 07:00:00  0.411388  0.313560       0.0825     0.1850\n",
      "2    2018-05-15 07:30:00  0.541886  0.720833       0.0675     0.2050\n",
      "3    2018-05-15 08:00:00  0.517726  0.699600       0.0675     0.1950\n",
      "4    2018-05-15 08:30:00  0.497936  0.665552       0.0675     0.1950\n",
      "...                  ...       ...       ...          ...        ...\n",
      "3727 2018-07-31 22:00:00  1.559391  1.201233       0.0975     0.1550\n",
      "3728 2018-07-31 22:30:00  1.597442  1.169718       0.0975     0.1550\n",
      "3729 2018-07-31 23:00:00  1.632354  1.201932       0.0925     0.1450\n",
      "3730 2018-07-31 23:30:00  1.440597  1.235055       0.0975     0.1450\n",
      "3731 2018-08-01 00:00:00  1.605628  1.076550       0.0975     0.1550\n",
      "\n",
      "[3732 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def process_wave_data(folder_path=\".\"):\n",
    "    \"\"\"\n",
    "    Process wave data from .nc files in the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing .nc files. Defaults to the current directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the processed results with columns:\n",
    "                      [\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"].\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(columns=[\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"])  # Initialize an empty DataFrame\n",
    "    files = glob.glob(f\"{folder_path}/*.nc\")  # Get all .nc files in the folder\n",
    "\n",
    "    for file in files:\n",
    "        data = xr.open_dataset(file)\n",
    "        date = pd.to_datetime(data.time.values)  # Convert date array to datetime\n",
    "        S = data.SmaxXpsd.values  # Extract SmaxXpsd array\n",
    "        f = data.Frequency.values  # Extract frequency array\n",
    "        spec = (S[:, 1:] + S[:, :63]) * 0.5\n",
    "        freq = (f[1:] + f[:63]) * 0.5\n",
    "        df = np.diff(f)\n",
    "        fup_indices = np.where(freq <= 0.5)[0]\n",
    "        fup = freq[fup_indices]\n",
    "\n",
    "        for i in range(len(S)):\n",
    "            spec_row = spec[i, :]\n",
    "            m1fstar = np.zeros(len(fup))\n",
    "            mminus1fstar = np.zeros(len(fup))\n",
    "            time = date[i]\n",
    "\n",
    "            for j in range(len(fup)):\n",
    "                m1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** 1 * df[j:len(fup)])\n",
    "                mminus1fstar[j] = np.sum(spec_row[j:len(fup)] * freq[j:len(fup)] ** (-1) * df[j:len(fup)])\n",
    "\n",
    "            with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "                alfafstar = m1fstar / np.sqrt(mminus1fstar)\n",
    "\n",
    "            if np.all(np.isnan(alfafstar)):\n",
    "                continue\n",
    "\n",
    "            loc1 = np.nanargmax(alfafstar)\n",
    "            fm = fup[loc1]\n",
    "\n",
    "            fseparation = 24.2084 * fm**3 - 9.2021 * fm**2 + 1.8906 * fm - 0.04286\n",
    "            spec_trimmed = spec_row[0:len(fup)]\n",
    "            spec_df = pd.DataFrame(spec_trimmed)\n",
    "            fup_df = pd.DataFrame(fup)\n",
    "\n",
    "            f_swell = fup_df[fup_df[0] < fseparation].dropna()\n",
    "            f_sea = fup_df[fup_df[0] > fseparation].dropna()\n",
    "\n",
    "            if fseparation > 0.025:\n",
    "                df_swell = f_swell.diff()\n",
    "                df_sea = f_sea.diff()\n",
    "                spec_swell = spec_df.loc[f_swell.index]\n",
    "                spec_sea = spec_df.loc[f_sea.index]\n",
    "\n",
    "                # Extract scalar values for fswell_peak and fsea_peak\n",
    "                fswell_peak = f_swell.loc[spec_swell.idxmax()[0]].values[0]  # Extract scalar value\n",
    "                fsea_peak = f_sea.loc[spec_sea.idxmax()[0]].values[0]  # Extract scalar value\n",
    "\n",
    "                Hs_swell = 4 * np.sqrt(np.nansum(spec_swell.values.flatten() * df_swell.values.flatten()))\n",
    "                Hs_sea = 4 * np.sqrt(np.nansum(spec_sea.values.flatten() * df_sea.values.flatten()))\n",
    "\n",
    "                # Append results to the DataFrame\n",
    "                results = pd.concat(\n",
    "                    [results, pd.DataFrame([[time, Hs_swell, Hs_sea, fswell_peak, fsea_peak]], columns=[\"Date\", \"Hs_swell\", \"Hs_sea\", \"fswell_peak\", \"fsea_peak\"])],\n",
    "                    ignore_index=True\n",
    "                )\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"/mnt/e/OneDrive/WORK/Projects/WRB_Dataprocessing\"\n",
    "wave_data = process_wave_data(folder_path)\n",
    "print(wave_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccb58a-7e3d-4611-94ba-fa2e4943c15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321ec98-367f-416c-938b-3d8def499713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
